{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import  ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/4d/8393a4f9d7113c2f0db341aea7d312ae7fb41288ce867b72c8940ebddf01/torch-1.8.1-cp37-cp37m-win_amd64.whl (190.5MB)\n",
      "Requirement already satisfied: numpy in b:\\anaconda\\lib\\site-packages (from torch) (1.16.2)\n",
      "Collecting typing-extensions (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Installing collected packages: typing-extensions, torch\n",
      "Successfully installed torch-1.8.1 typing-extensions-3.7.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/f6/6a7d86254981c28a1a9230b087db34a5429b66578bbc9d3a70d40ebbeef4/torchvision-0.9.1-cp37-cp37m-win_amd64.whl (852kB)\n",
      "Requirement already satisfied: numpy in b:\\anaconda\\lib\\site-packages (from torchvision) (1.16.2)\n",
      "Requirement already satisfied: torch==1.8.1 in b:\\anaconda\\lib\\site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in b:\\anaconda\\lib\\site-packages (from torchvision) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in b:\\anaconda\\lib\\site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aed6fdefdc4f79bf0384eb80c487ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9912422), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1a1491a1c24471b912240c73097206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28881), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a639b058e49a4455ad7dda5721d771a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1648877), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9f68b9ea1e4aee9c2e713a45961dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4542), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#MNIST 数据集\n",
    "#设置训练的批次大小、学习率、及训练代数\n",
    "batch_size=200\n",
    "learning_rate=0.001\n",
    "epochs=20\n",
    "\n",
    "\n",
    "#下载数据集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成 三个神经网络成，对应感知节分别为第一层100，第二成200，第三层10，即要分类的数目\n",
    "w1, b1 = torch.randn(100, 784, requires_grad=True),\\\n",
    "         torch.zeros(100, requires_grad=True)\n",
    "w2, b2 = torch.randn(200, 100, requires_grad=True),\\\n",
    "         torch.zeros(200, requires_grad=True)\n",
    "w3, b3 = torch.randn(10, 200, requires_grad=True),\\\n",
    "         torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义前向网络计算，每层神经网络输出后增加relu激活函数，确保网络的非线性，实现更好的分类效果\n",
    "def forward(x):\n",
    "    x = x@w1.t() + b1\n",
    "    x = F.relu(x)\n",
    "    x = x@w2.t() + b2\n",
    "    x = F.relu(x)\n",
    "    x = x@w3.t() + b3\n",
    "    x = F.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器，采用SGD随机梯度下降的方式对w1, b1, w2, b2, w3, b3进行优化\n",
    "optimizer = optim.SGD([w1, b1, w2, b2, w3, b3], lr=learning_rate)\n",
    "#定义采用交叉熵作为损失函数\n",
    "criteon = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练代数: 0 [0/60000 (0%)]\tLoss: 2010.320435\n",
      "训练代数: 0 [5000/60000 (8%)]\tLoss: 24.145620\n",
      "训练代数: 0 [10000/60000 (17%)]\tLoss: 10.370474\n",
      "训练代数: 0 [15000/60000 (25%)]\tLoss: 4.403249\n",
      "训练代数: 0 [20000/60000 (33%)]\tLoss: 4.524137\n",
      "训练代数: 0 [25000/60000 (42%)]\tLoss: 5.080046\n",
      "训练代数: 0 [30000/60000 (50%)]\tLoss: 2.785926\n",
      "训练代数: 0 [35000/60000 (58%)]\tLoss: 6.190485\n",
      "训练代数: 0 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 0 [45000/60000 (75%)]\tLoss: 4.070419\n",
      "训练代数: 0 [50000/60000 (83%)]\tLoss: 2.279557\n",
      "训练代数: 0 [55000/60000 (92%)]\tLoss: 2.291070\n",
      "\n",
      "测试集: Average loss: 0.0135, Accuracy: 985/10000 (10%)\n",
      "\n",
      "训练代数: 1 [0/60000 (0%)]\tLoss: 4.840629\n",
      "训练代数: 1 [5000/60000 (8%)]\tLoss: 2.836610\n",
      "训练代数: 1 [10000/60000 (17%)]\tLoss: 2.291070\n",
      "训练代数: 1 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 1 [20000/60000 (33%)]\tLoss: 2.294051\n",
      "训练代数: 1 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 1 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 1 [35000/60000 (58%)]\tLoss: 2.527578\n",
      "训练代数: 1 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 1 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 1 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 1 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0120, Accuracy: 983/10000 (10%)\n",
      "\n",
      "训练代数: 2 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 2 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 2 [10000/60000 (17%)]\tLoss: 2.636094\n",
      "训练代数: 2 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 2 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 2 [25000/60000 (42%)]\tLoss: 2.968201\n",
      "训练代数: 2 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 2 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 2 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 2 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 2 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 2 [55000/60000 (92%)]\tLoss: 2.291070\n",
      "\n",
      "测试集: Average loss: 0.0117, Accuracy: 983/10000 (10%)\n",
      "\n",
      "训练代数: 3 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 3 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 3 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 3 [15000/60000 (25%)]\tLoss: 5.203221\n",
      "训练代数: 3 [20000/60000 (33%)]\tLoss: 2.291070\n",
      "训练代数: 3 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 3 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 3 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 3 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 3 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 3 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 3 [55000/60000 (92%)]\tLoss: 2.291070\n",
      "\n",
      "测试集: Average loss: 0.0116, Accuracy: 982/10000 (10%)\n",
      "\n",
      "训练代数: 4 [0/60000 (0%)]\tLoss: 3.508485\n",
      "训练代数: 4 [5000/60000 (8%)]\tLoss: 2.291070\n",
      "训练代数: 4 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 4 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 4 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 4 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 4 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 4 [35000/60000 (58%)]\tLoss: 2.291070\n",
      "训练代数: 4 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 4 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 4 [50000/60000 (83%)]\tLoss: 3.007873\n",
      "训练代数: 4 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0116, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 5 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 5 [5000/60000 (8%)]\tLoss: 2.291070\n",
      "训练代数: 5 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 5 [15000/60000 (25%)]\tLoss: 2.291070\n",
      "训练代数: 5 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 5 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 5 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 5 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 5 [40000/60000 (67%)]\tLoss: 2.291070\n",
      "训练代数: 5 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 5 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 5 [55000/60000 (92%)]\tLoss: 2.279557\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 6 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 6 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 6 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 6 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 6 [20000/60000 (33%)]\tLoss: 2.347346\n",
      "训练代数: 6 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 6 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 6 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 6 [40000/60000 (67%)]\tLoss: 3.682165\n",
      "训练代数: 6 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 6 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 6 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 7 [0/60000 (0%)]\tLoss: 2.291070\n",
      "训练代数: 7 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 7 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 7 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 7 [20000/60000 (33%)]\tLoss: 2.902903\n",
      "训练代数: 7 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 7 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 7 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 7 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 7 [45000/60000 (75%)]\tLoss: 4.190470\n",
      "训练代数: 7 [50000/60000 (83%)]\tLoss: 2.279642\n",
      "训练代数: 7 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 8 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 8 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 8 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 8 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 8 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 8 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 8 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 8 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 8 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 8 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 8 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 8 [55000/60000 (92%)]\tLoss: 2.291070\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 9 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 9 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 9 [10000/60000 (17%)]\tLoss: 2.375249\n",
      "训练代数: 9 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 9 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 9 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 9 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 9 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 9 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 9 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 9 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 9 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 10 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 10 [5000/60000 (8%)]\tLoss: 2.268044\n",
      "训练代数: 10 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 10 [15000/60000 (25%)]\tLoss: 3.177921\n",
      "训练代数: 10 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 10 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 10 [30000/60000 (50%)]\tLoss: 2.291070\n",
      "训练代数: 10 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 10 [40000/60000 (67%)]\tLoss: 3.608993\n",
      "训练代数: 10 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 10 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 10 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 11 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 11 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 11 [10000/60000 (17%)]\tLoss: 2.291070\n",
      "训练代数: 11 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 11 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 11 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 11 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 11 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 11 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 11 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 11 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 11 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 12 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 12 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 12 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 12 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 12 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 12 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 12 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 12 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 12 [40000/60000 (67%)]\tLoss: 2.291070\n",
      "训练代数: 12 [45000/60000 (75%)]\tLoss: 2.291070\n",
      "训练代数: 12 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 12 [55000/60000 (92%)]\tLoss: 2.291070\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 13 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 13 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 13 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 13 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 13 [20000/60000 (33%)]\tLoss: 2.291070\n",
      "训练代数: 13 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 13 [30000/60000 (50%)]\tLoss: 3.237805\n",
      "训练代数: 13 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 13 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 13 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 13 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 13 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 14 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 14 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 14 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 14 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 14 [20000/60000 (33%)]\tLoss: 2.302583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练代数: 14 [25000/60000 (42%)]\tLoss: 2.291070\n",
      "训练代数: 14 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 14 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 14 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 14 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 14 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 14 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 15 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 15 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 15 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 15 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 15 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 15 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 15 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 15 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 15 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 15 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 15 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 15 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 16 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 16 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 16 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 16 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 16 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 16 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 16 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 16 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 16 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 16 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 16 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 16 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 17 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 17 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 17 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 17 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 17 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 17 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 17 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 17 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 17 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 17 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 17 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 17 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 18 [0/60000 (0%)]\tLoss: 2.302583\n",
      "训练代数: 18 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 18 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 18 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 18 [20000/60000 (33%)]\tLoss: 2.302583\n",
      "训练代数: 18 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 18 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 18 [35000/60000 (58%)]\tLoss: 2.302583\n",
      "训练代数: 18 [40000/60000 (67%)]\tLoss: 2.291070\n",
      "训练代数: 18 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 18 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 18 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n",
      "训练代数: 19 [0/60000 (0%)]\tLoss: 2.291070\n",
      "训练代数: 19 [5000/60000 (8%)]\tLoss: 2.302583\n",
      "训练代数: 19 [10000/60000 (17%)]\tLoss: 2.302583\n",
      "训练代数: 19 [15000/60000 (25%)]\tLoss: 2.302583\n",
      "训练代数: 19 [20000/60000 (33%)]\tLoss: 2.291070\n",
      "训练代数: 19 [25000/60000 (42%)]\tLoss: 2.302583\n",
      "训练代数: 19 [30000/60000 (50%)]\tLoss: 2.302583\n",
      "训练代数: 19 [35000/60000 (58%)]\tLoss: 2.291070\n",
      "训练代数: 19 [40000/60000 (67%)]\tLoss: 2.302583\n",
      "训练代数: 19 [45000/60000 (75%)]\tLoss: 2.302583\n",
      "训练代数: 19 [50000/60000 (83%)]\tLoss: 2.302583\n",
      "训练代数: 19 [55000/60000 (92%)]\tLoss: 2.302583\n",
      "\n",
      "测试集: Average loss: 0.0115, Accuracy: 981/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#设置迭代次数\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #将数据打平为（批次，高度*宽度），-1代表所有\n",
    "        data = data.view(-1, 28*28)\n",
    "\n",
    "        #将数据输入到网络中\n",
    "        cal_data = forward(data)\n",
    "        #将计算的数据与目标数据求误差损失\n",
    "        loss = criteon(cal_data, target)\n",
    "\n",
    "        #将梯度值初始化为0\n",
    "        optimizer.zero_grad()\n",
    "        #pytorch计算梯度值\n",
    "        loss.backward()\n",
    "        #更新梯度值\n",
    "        optimizer.step()\n",
    "        #每隔25*batcsize(200) = 5000 打印输出结果\n",
    "        if batch_idx % 25 == 0:\n",
    "            print('训练代数: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    #将测试误差及正确率清0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    #取测试集数据及目标数据\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        logits = forward(data)\n",
    "        #误差累加\n",
    "        test_loss += criteon(logits, target).item()\n",
    "        #取出预测最大值的索引编号，即预测值\n",
    "        pred = logits.data.argmax(dim=1)\n",
    "        #统计正确预测的个数\n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    #打印输出测试误差及准确率\n",
    "    print('\\n测试集: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
